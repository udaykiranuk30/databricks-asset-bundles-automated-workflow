# Databricks notebook source
# MAGIC %md
# MAGIC ### Example Exploratory Notebook
# MAGIC
# MAGIC Use this notebook to explore the data generated by the pipeline in your preferred programming language.
# MAGIC
# MAGIC **Note**: This notebook is not executed as part of the pipeline.

# COMMAND ----------

yellowdf= spark.read.format("csv").option("header","true").option("inferSchema","true").load("/Volumes/dab_nyctaxi_dev_uday/default/nyctaxi_trips_data/yellow/")

# COMMAND ----------

# MAGIC %py 
# MAGIC display(yellowdf.limit(10))

# COMMAND ----------

greendf= spark.read.format("csv").option("header","true").option("inferSchema","true").load("/Volumes/dab_nyctaxi_dev_uday/default/nyctaxi_trips_data/green/")

# COMMAND ----------

filtergreendf = greendf.filter(
    "DOLocationID IN (1,2,3,4,5,6,7,8,9,10)"
)
display(filtergreendf)

# COMMAND ----------

print(yellowdf.printSchema())


# COMMAND ----------

paymenttypedf=spark.read.format("json").option("inferSchema","true").load("/Volumes/dab_nyctaxi_dev_uday/default/nyctaxi_trips_data/common/PaymentTypes/")

# COMMAND ----------

display(paymenttypedf.limit(10))

# COMMAND ----------

ratecodesdf=spark.read.format("csv").option("header","true").option("inferSchema","true").load("/Volumes/dab_nyctaxi_dev_uday/default/nyctaxi_trips_data/common/RateCodes/")

# COMMAND ----------

display(ratecodesdf.limit(10))

# COMMAND ----------

taxizonesdf=spark.read.format("csv").option("header","true").option("inferSchema","true").load("/Volumes/dab_nyctaxi_dev_uday/default/nyctaxi_trips_data/common/TaxiZones/")

# COMMAND ----------

display(taxizonesdf.limit(10))

# COMMAND ----------

if yellowdf.schema == greendf.schema:
    print("Schemas are equal")
else:
    print("Schemas are different")


# COMMAND ----------

print(greendf.printSchema())

# COMMAND ----------


